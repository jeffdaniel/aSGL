% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/asgl.R
\name{asgl}
\alias{asgl}
\title{Fit a GLM with Adaptive Sparse Group Lasso Penalty}
\usage{
asgl(x, y, index, family = c("gaussian", "binomial"), offset = NULL,
  alpha = 0.95, lambda = NULL, lambda_min = 0.1, nlambda = 20,
  maxit = 1000, thresh = 0.001, gamma = 0.8, step = 1,
  standardize = FALSE, grp_weights = NULL, ind_weights = NULL)
}
\arguments{
\item{x}{Input matrix of dimensions \emph{n} by \emph{p}.}

\item{y}{Response vector of length \emph{n}. For linear models
(\code{family = "gaussian"}), a numeric vector; for logistic models
(\code{family = "binomial"}), a categorical factor with two levels.}

\item{index}{A vector of length \emph{p} defining group membership for each
covariate.}

\item{family}{Response type. One of \code{"gaussian"} or \code{"binomial"}.}

\item{offset}{Optional. A vector of length \emph{n} to be included in the
linear predictor}

\item{alpha}{Penalty mixing parameter. The penalty reduces to the adaptive
group lasso if \code{alpha = 0} and to the adaptive lasso if
\code{alpha = 0}.}

\item{lambda}{Optional. A vector of user-specified penalty tuning parameter
values at which to fit model. If \code{NULL}, the sequence is chosen
automatically (recommended).}

\item{lambda_min}{Smallest tuning parameter value, as a fraction of the
largest parameter value in the sequence (the smallest value for which
all coefficients are zero).}

\item{nlambda}{The number of tuning parameter values in the sequence.}

\item{maxit}{Maximum number of iterations until convergence}

\item{thresh}{Convergence threshold for change in model coefficient values.}

\item{gamma}{Backtracking parameter for use in gradient descent step}

\item{step}{Initial gradient descent step size.}

\item{standardize}{If \code{TRUE}, variables are standardized prior to model
fitting.}

\item{grp_weights}{A vector of weights for each group of coefficients, the
same length as \code{index}.}

\item{ind_weights}{A vector of weights for each indiviual coefficient, of
length \emph{p}.}
}
\value{
An object of class "\code{asgl}"
}
\description{
Fit a generalized linear model via penalized maximum likelihood. The
regularization path is computed for the adaptive sparse group lasso penalty
along a sequence of tuning parameter values. Supports linear and logistic
regression.
}
\examples{
# linear regression
n <- 500; p <- 20; groupsize <- 5
index <- ceiling(1:p / groupsize)
beta <- (-2:2)
x <- matrix(rnorm(n * p), ncol = p, nrow = n)
y <- as.vector(x[,1:5] \%*\% beta + 0.1 * rnorm(n))
asgl(x, y, index, family = "gaussian")

# logistic regression
eta <- x[, 1:5] \%*\% beta
prob <- exp(eta) / (1 + exp(eta))
y <- rbinom(n, 1, prob)
asgl(x, y, index, family = "binomial")

# adaptive weights
coefs <- glm.fit(x, y, family = binomial())$coefficients
ind_weights <- 1 / abs(coefs)
grp_weights <- numeric(length(unique(index)))
for (i in unique(index)) {
  grp_weights[i] <-  1 / sqrt(sum(coefs[which(index == i)]^2))
}
asgl(x, y, index, family = "binomial",
     grp_weights = grp_weights, ind_weights = ind_weights)

}
